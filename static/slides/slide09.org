#+TITLE: 判別分析 
#+SUBTITLE: 評価
#+AUTHOR: 村田 昇
#+EMAIL: noboru.murata@eb.waseda.ac.jp
#+DATE: 2020.11.27
:reveal:
#+INCLUDE: "./reveal.js/org/mycourse.org"
#+STARTUP: hidestars content
# C-c C-x C-v でinlineを切り替え
# <m C-i でlatex block (math env用)
# C-c '
:end:

#+begin_src R :eval no :exports none :tangle yes
  ### 第09回 練習問題解答例
#+end_src
#+begin_src R :exports none
  setwd("~/Desktop/lectures/u-tokyo/autumn/slide")
#+end_src

* 講義の予定
  - 第1日: 判別分析の考え方
  - *第2日: 判別分析の評価*


* 判別分析の復習
** 判別分析
   - 個体の特徴量から
     その個体の属するクラスを予測する関係式を構成
   - *事前確率*: $\pi_k=P(Y=k)$ (prior probability)
     - $X=\boldsymbol{x}$ が与えられる前に予測されるクラス
   - *事後確率*: $p_k(\boldsymbol{x})$ (posterior probability)
     - $X=\boldsymbol{x}$ が与えられた後に予測されるクラス
       #+begin_quote
       #+begin_src latex
         \begin{equation}
           p_k(\boldsymbol{x}):=P(Y=k|X=\boldsymbol{x})
         \end{equation}
       #+end_src
       #+end_quote
     - 所属する確率が最も高いクラスに個体を分類
** 判別関数
   - 判別の手続き
     - 説明変数 $X=\boldsymbol{x}$ の取得
     - 事後確率 $p_k(\boldsymbol{x})$ の計算
     - 事後確率最大のクラスにデータを分類
   - *判別関数*: $\delta_k(\boldsymbol{x})$ ($k=1,\dots,K$)
     #+begin_quote
     #+begin_src latex
       \begin{equation}
         p_k(\boldsymbol{x}) 
         < 
         p_l(\boldsymbol{x})
         \Leftrightarrow
         \delta_k(\boldsymbol{x})
         <
         \delta_l(\boldsymbol{x})
       \end{equation}
     #+end_src
     #+end_quote
     事後確率の順序を保存する計算しやすい関数
   - 判別関数 $\delta_k(\boldsymbol{x})$ を最大化するようなクラス $k$ に分類
** 線形判別
   - $f_k(\boldsymbol{x})$ の仮定:
     - $q$ 変量正規分布の密度関数
     - 平均ベクトル $\boldsymbol{\mu}_k$: クラスごとに異なる
     - 共分散行列 $\Sigma$: *すべてのクラスで共通*
       #+begin_quote
       #+begin_src latex
         \begin{equation}
           f_k(\boldsymbol{x})
           =
           \frac{1}{(2\pi)^{q/2}\sqrt{\det\Sigma}}
           \exp\left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu}_k)^{\mathsf{T}}
             \Sigma^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_k)\right)
         \end{equation}
       #+end_src
       #+end_quote
   - 線形判別関数: $\boldsymbol{x}$ の1次式
     # (linear discriminant function)
     #+begin_quote
     #+begin_src latex
       \begin{equation}
         \delta_k(\boldsymbol{x})
         =
         \boldsymbol{x}^{\mathsf{T}}\Sigma^{-1}\boldsymbol{\mu}_k
         -\frac{1}{2}\boldsymbol{\mu}_k^{\mathsf{T}}\Sigma^{-1}\boldsymbol{\mu}_k
         +\log\pi_k
       \end{equation}
     #+end_src
     #+end_quote
     
** 2次判別
   - $f_k(\boldsymbol{x})$ の仮定:
     - $q$ 変量正規分布の密度関数
     - 平均ベクトル $\boldsymbol{\mu}_k$: クラスごとに異なる
     - 共分散行列 $\Sigma_k$: *クラスごとに異なる*
       #+begin_quote
       #+begin_src latex
         \begin{equation}
           f_k(\boldsymbol{x})
           =
           \frac{1}{(2\pi)^{q/2}\sqrt{\det\Sigma_k}}
           \exp\left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu}_k)^{\mathsf{T}}
             \Sigma_k^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_k)\right)
         \end{equation}
       #+end_src
       #+end_quote
   - 2次判別関数: $\boldsymbol{x}$ の2次式
     #+begin_quote
     #+begin_src latex
     \begin{equation}
       \delta_k(\boldsymbol{x})
       =
       -\frac{1}{2}\det\Sigma_k
       -\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu}_k)^{\mathsf{T}}
       \Sigma_k^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_k)
       +\log\pi_k
     \end{equation}
     #+end_src
     #+end_quote
     
** Fisherの線形判別
   - 新しい特徴量 $Z=\boldsymbol{\alpha}^{\mathsf{T}} X$ を考える
   - 良い $Z$ の基準:
     - クラス内では集まっているほど良い (\(\boldsymbol{\alpha}^{\mathsf{T}} W\boldsymbol{\alpha}\)は小)
     - クラス間では離れているほど良い (\(\boldsymbol{\alpha}^{\mathsf{T}} B\boldsymbol{\alpha}\)は大)
   - Fisherの基準:
     #+begin_quote
     #+begin_src latex
       \begin{equation}
         \text{maximize}\quad \boldsymbol{\alpha}^{\mathsf{T}} B\boldsymbol{\alpha}
         \quad\text{s.t.}\quad \boldsymbol{\alpha}^{\mathsf{T}} W\boldsymbol{\alpha}=\text{const.}
       \end{equation}
     #+end_src
     #+end_quote
   - $\boldsymbol{\alpha}$ は $W^{-1}B$ の第1から第 $K-1$ 固有ベクトル
   - 判別方法: 特徴量の距離を用いる
     - $d_{k}=\sum_{l=1}^{K-1}(\alpha_l^{\mathsf{T}}\boldsymbol{x}-\alpha_l^{\mathsf{T}}\mu_k)^2$ 
       が最小のとなるクラス $k$ に判別


* 2値判別分析の評価
** 誤り率
   - 単純な誤り:
     #+begin_quote
     #+begin_src latex
       \begin{equation}
         \text{(誤り率)}
         =\frac{\text{(誤って判別されたデータ数)}}
         {\text{(全データ数)}}
       \end{equation}
     #+end_src
     #+end_quote
   - 判別したいラベル: 陽性 (positive)
     - *真陽性*: 正しく陽性と判定 (true positive; TP)
     - *偽陽性*: 誤って陽性と判定 (false positive; FP) (*第I種過誤*)
     - *偽陰性*: 誤って陰性と判定 (false negative; FN) (*第II種過誤*)
     - *真陰性*: 正しく陰性と判定 (true negative; TN) 

** 混同行列
   |------------+-------------------------+-------------------------|
   |            | 真値は陽性              | 真値は陰性              |
   |------------+-------------------------+-------------------------|
   | 判別は陽性 | 真陽性 (True Positive)  | 偽陽性 (False Positive) |
   | 判別は陰性 | 偽陰性 (False Negative) | 真陰性 (True Negative)  |
   |------------+-------------------------+-------------------------|
   - *confusion matrix*
   - 転置で書く流儀もあるので注意

** 混同行列 
   |------------+-------------------------+-------------------------|
   |            | 判別は陽性              | 判別は陰性              |
   |------------+-------------------------+-------------------------|
   | 真値は陽性 | 真陽性 (True Positive)  | 偽陰性 (False Negative) |
   | 真値は陰性 | 偽陽性 (False Positive) | 真陰性 (True Negative)  |
   |------------+-------------------------+-------------------------|
   - パターン認識や機械学習で多く見られた書き方
   - 誤差行列 (error matrix) とも呼ばれる

** 基本的な評価基準
   - 定義
     #+begin_quote
     #+begin_src latex
       \begin{align}
         \text{(真陽性率)}
         &=\frac{TP}{TP+FN} \qquad\text{(true positive rate)}\\
         \text{(真陰性率)}
         &=\frac{TN}{FP+TN} \qquad\text{(true negative rate)}\\
         \text{(適合率)}
         &=\frac{TP}{TP+FP} \qquad\text{(precision)}\\
         \text{(正答率)}
         &=\frac{TP+TN}{TP+FP+TN+FN} \qquad\text{(accuracy)}
       \end{align}
     #+end_src
     #+end_quote
   #+reveal: split
   - 別名 (分野で異なるので注意)
     - 感度 (sensitivity) あるいは 再現率 (recall):
       #+begin_quote
       #+begin_src latex
         \begin{equation}
           \text{(真陽性率)}
           =\frac{TP}{TP+FN}
         \end{equation}
       #+end_src
       #+end_quote
     - 特異度 (specificity):
       #+begin_quote
       #+begin_src latex
         \begin{equation}
           \text{(真陰性率)}
           =\frac{TN}{FP+TN}
         \end{equation}
       #+end_src
       #+end_quote
     - 精度:
       #+begin_quote
       #+begin_src latex
         \begin{equation}
           \text{(正答率)}
           =\frac{TP+TN}{TP+FP+TN+FN}
         \end{equation}
       #+end_src
       #+end_quote

** F-値
   - *F-measure, F-score*
   - 定義
     #+begin_quote
     #+begin_src latex
       \begin{align}
         F_{1}&=\frac{2}{{1}/{\text{(再現率)}}+{1}/{\text{(適合率)}}}\\
         F_{\beta}&=\frac{\beta^{2}+1}{{\beta^{2}}/{\text{(再現率)}}+{1}/{\text{(適合率)}}}
       \end{align}
     #+end_src
     再現率(真陽性率)と適合率の(重み付き)調和平均
     #+end_quote

** Cohen の kappa 値
   - Cohen's *kappa measure*
   - 定義
     #+begin_quote
     #+begin_src latex
       \begin{align}
         p_{o}
         &=\frac{TP+TN}{TP+FP+TN+FN} \qquad\text{(accuracy)}\\
         p_{e}
         &=\frac{TP+FP}{TP+FP+TN+FN}\cdot\frac{TP+FN}{TP+FP+TN+FN}\\
         &\quad
           +\frac{FN+TN}{TP+FP+TN+FN}\cdot\frac{FP+TN}{TP+FP+TN+FN}\\
         \kappa
         &=
           \frac{p_{o}-p_{e}}{1-p_{e}}
           =
           1-\frac{1-p_{o}}{1-p_{e}}
       \end{align}
     #+end_src
     観測された精度と偶然の精度の比較
     #+end_quote


* 実習
** R: 精度の計算
   - 基本的な評価値の計算
     #+begin_src R :eval no
       ## myData に集計されている label をそれ以外のデータで予測する
       est <- lda(label ~ ., data=myData) # qdaも同様
       prd <- predict(est)
       ## 混同行列の作成
       ctab <- table(prection=prd$class,truth=myData$label)
       etab <- table(truth=myData$label,prection=prd$class)
       ## TP,FP など値の取得
       tp <- ctab[1,1] 
       fp <- ctab[1,2] # etab[2,1]
     #+end_src
     
** 練習問題
   :PROPERTIES:
   :reveal_background: #fef4f4
   :END:
   - 前回と同様に東京の気候データを用いて以下を確認しなさい
     - 9月と10月の気温と湿度のデータを抽出する
       #+begin_src R :eval no
	 TW.data <- transform(read.csv("data/tokyo_weather_reg.csv"),
			      month=substr(as.Date(date),6,7)) # 月を切り出し
	 TW.subset  <- transform(subset(TW.data,
					subset= month %in% c("09","10"),
					select=c(temp,humid,month)),
				 month=as.factor(month)) # 因子にする
       #+end_src
     - 全てのデータを用いて判別関数を構成する
     - 構成した判別関数の評価を行う
     #+begin_src R :eval no :exports none :tangle yes
       ### 練習1.1
       ### 判別結果の評価

       ### 東京の気象データによる判別分析
       library(MASS)

       ## 9月と10月の判別の例
       ## データの整理
       TW.data <- transform(read.csv("data/tokyo_weather_reg.csv"),
			    month=substr(as.Date(date),6,7)) # 月を切り出し
       TW.subset  <- transform(subset(TW.data,
				      subset= month %in% c("09","10"),
				      select=c(temp,humid,month)),
			       month=as.factor(month)) # 因子にする
       ## 判別関数を作成
       TW.lda <- lda(month ~ temp + humid, data=TW.subset)
       TW.qda <- qda(month ~ temp + humid, data=TW.subset)
       ## 判別結果の評価
       TW.lest <- predict(TW.lda)
       TW.qest <- predict(TW.qda)

       ## 混同行列の作成
       (ltab <- table(Prediction=TW.lest$class,
                      Truth=TW.subset$month))
       (qtab <- table(Prediction=TW.qest$class,
                      Truth=TW.subset$month))
       ## positive=9月とする
       ## 線形判別の評価
       ltab[1,1] # 真陽性 true positive
       ltab[1,2] # 偽陽性 false positive
       ltab[2,1] # 偽陰性 false negative
       ltab[2,2] # 真陰性 true negative
       (ltab[1,1]+ltab[2,2])/sum(ltab) # 精度 accuracy
       sum(diag(ltab))/sum(ltab) # 上記と同様，行列のように扱うことも可能
       ltab[1,1]/sum(ltab[1,]) # 適合率 precision
       ## 2次判別の評価
       sum(diag(qtab))/sum(qtab) # 精度
       
       ### 判別境界の可視化の例
       ## 準備
       myPch <- c(16,17) # 塗り潰し丸(9月)，三角(10月)
       myCol <- c("red","green") # 赤(9月)，緑(10月)
       myBg <- c(rgb(1,0,0,0.1), rgb(0,1,0,0.1)) # 薄赤(9月)，薄緑(10月)
       sx <- pretty(with(TW.subset,range(temp)), 120)
       sy <- pretty(with(TW.subset,range(humid)), 120)
       myGrid <- expand.grid(temp=sx,humid=sy)

       ## 線形判別
       with(TW.subset, 
            plot(temp, humid, # 試験データの散布図
                 pch=myPch[month], col=myCol[month],
                 xlab="temperature", ylab="humidity",
                 main="linear discriminant"))
       ## 誤ったデータを表示
       with(TW.subset[TW.lest$class!=TW.subset$month,], 
	    points(temp, humid, 
		   pch=1, col="orchid", cex=2, lwd=2))
       ## 判別されるラベルごとに背景を着色
       image(x=sx, y=sy, add=TRUE, col=myBg,
             z=matrix(as.numeric(predict(TW.lda,newdata=myGrid)$class),
                      length(sx), length(sy)))

       ## 2次判別
       with(TW.subset, 
            plot(temp, humid, # 試験データの散布図
                 pch=myPch[month], col=myCol[month],
                 xlab="temperature", ylab="humidity",
                 main="quadratic discriminant"))
       ## 誤ったデータを表示
       with(TW.subset[TW.qest$class!=TW.subset$month,], 
	    points(temp, humid, 
		   pch=1, col="orchid", cex=2, lwd=2))
       ## 判別されるラベルごとに背景を着色
       image(x=sx, y=sy, add=TRUE, col=myBg,
             z=matrix(as.numeric(predict(TW.qda,newdata=myGrid)$class),
                      length(sx), length(sy)))
       
       ## 後述する caret package を使う場合
       library(caret)
       confusionMatrix(TW.lest$class, TW.subset$month) # 線形
       confusionMatrix(TW.qest$class, TW.subset$month) # 2次

       ## 12ヶ月分のデータを用いた例 (説明変数は適宜選択せよ)
       TW.subset  <- transform(subset(TW.data,
				      select=c(temp,solar,wind,humid,month)),
			       month=as.factor(month)) 
       ## 判別関数を作成
       TW.lda <- lda(month ~ ., # 右辺の . は month 以外の全てを説明変数として指定
		     data=TW.subset)
       ## 判別結果の評価
       TW.est <- predict(TW.lda)
       confusionMatrix(TW.est$class, TW.subset$month)
       confusionMatrix(TW.est$class, TW.subset$month)$table
       confusionMatrix(TW.est$class, TW.subset$month)$overall
       confusionMatrix(TW.est$class, TW.subset$month)$byClass
     #+end_src

** R: 混同行列 ~caret::confusionMatrix()~
   - ~caret~: 評価のためのパッケージ
   - 判別結果の評価
     #+begin_src R :eval no
       install.packages("caret") # 右下ペインの package タブから install
       library(caret) # または require(caret) 
       confusionMatrix(data, reference)
       ## data: 判別関数による予測ラベル (factor)
       ## referenc: 真のラベル (上と同じfactorである必要がある)
     #+end_src
   
** データセットの準備
   :PROPERTIES:
   :reveal_background: #fef4f4
   :END:
   - 以下のデータセットを使用します
     - ~winequality-red.~
       #+begin_quote
       UC Irvine Machine Learning Repository で公開されている
       Wine Quality Data Set の一部
       #+end_quote
       [[https://archive.ics.uci.edu/ml/datasets/Wine+Quality]]
     - 以下に download せずに読み込む方法を紹介します
       #+begin_src R :eval no
	 WQ.org <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv",
			    sep=";") # データの区切りが ";" となっている
	 WQ.data <- transform(WQ.org,
			      quality=as.factor( # qualityを再分類
				ifelse(quality %in% 7:10, "A",
				ifelse(quality %in% 5:6, "B" ,"C"))))
       #+end_src
** 練習問題
   :PROPERTIES:
   :reveal_background: #fef4f4
   :END:
   - Wine Quality Data Set を用いて
     以下を確認しなさい
     - 全てデータを用いて線形判別関数を構成し，評価を行う
     - 全てデータを用いて2次判別関数を構成し，評価を行う
     #+begin_src R :eval no :exports none :tangle yes
       ### 練習1.2
       ### 判別結果の評価

       ## Wine Quality Data Set を用いた判別分析
       WQ.org <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv",
			  sep=";")
       table(WQ.org$quality) 
       WQ.data <- transform(WQ.org,
			    quality=as.factor(
				ifelse(quality %in% 7:10, "A",
				ifelse(quality %in% 5:6, "B" ,"C"))))
       ## 判別関数を作成
       WQ.lda <- lda(quality ~ ., data=WQ.data)
       WQ.qda <- qda(quality ~ ., data=WQ.data)
       ## 判別結果の評価
       confusionMatrix(predict(WQ.lda)$class, WQ.data$quality)
       confusionMatrix(predict(WQ.qda)$class, WQ.data$quality)
     #+end_src

** COMMENT 演習: さまざまな評価値
   :PROPERTIES:
   :reveal_background: #EEEEFF
   :END:
   - 前回用いたデータについて，
     さまざまな評価値を計算してみよう


* 予測誤差
** 訓練誤差と予測誤差
  - *訓練誤差*:
    既知データに対する誤り (training error)
  - *予測誤差*:
    未知データに対する誤り (predictive error)
  - 訓練誤差は予測誤差より良くなることが多い 
  - 既知データの判別に特化している可能性がある
    - 過適応 (over-fitting)
    - 過学習 (over-training)

** 交叉検証
   - データを訓練データと試験データに分割して用いる
     - *訓練データ*:
       判別関数を構成する (training data)
     - *試験データ*:
       予測精度を評価する (test data)
   - データの分割に依存して予測誤差の評価が偏る
   - 偏りを避けるために複数回分割を行ない評価する
   - "交差"と書く場合もある
# データ分割の偏りによる精度評価の

** 交叉検証法
   - *cross-validation (CV)* 
   - \(k\)-重交叉検証法 (\(k\)-fold cross-validation; \(k\)-fold CV)
     - $n$ 個のデータを $k$ ブロックにランダムに分割
     - 第 $i$ ブロックを除いた $k-1$ ブロックで判別関数を推定
     - 除いておいた第 $i$ ブロックで予測誤差を評価
     - $i=1,\dotsc,k$ で繰り返し $k$ 個の予測誤差で評価 (平均や分散)
   - leave-one-out法 (leave-one-out CV; LOO-CV)
     - $k=n$ として上記を実行


* 実習
** R: ~for~ 文による交叉検証
   - LOO交叉検証法
     #+begin_src R :eval no
       ## myData に集計されている label をそれ以外のデータで予測する
       prd <- c() # ベクトルとして初期化
       for(i in 1:nrow(myData)) {
           est <- lda(label ~ ., data=myData, subset=-i)
           prd[i] <- predict(est, newdata=myData[i,])$class
       }
       ## prd には LOO交叉検証法による予測値が入っている
       table(prediction=prd, truth=myData$label)
     #+end_src
     
** R: ~for~ 文による交叉検証
   - k-重交叉検証法
     #+begin_src R :eval no
       ## myData に集計されている label をそれ以外のデータで予測する
       prd <- c()
       k <- 10 # ブロック数
       blk <- sample(k, nrow(myData), replace=TRUE) # ブロックをランダムに指定
       for(i in 1:k) {
           idx <- which(blk==i) # 第iブロックのデータ番号を取得
           est <- lda(label ~ ., data=myData, subset=-idx)
           prd[idx] <- predict(est, newdata=myData[idx,])$class
       }
       ## prd には k-重交叉検証法による予測値が入っている
       table(prediction=prd, truth=myData$label)
     #+end_src
** 練習問題
   :PROPERTIES:
   :reveal_background: #fef4f4
   :END:
   - 東京の気候データを用いた線形判別と2次判別において以下を確認しなさい
     - LOO交叉検証法を用いて予測誤差の比較を行いなさい
     - k-重交叉検証法を用いて予測誤差の比較を行いなさい
     #+begin_src R :eval no :exports none :tangle yes
       ### 練習2.1
       ### 予測誤差の評価

       ### 東京の気象データによる判別分析
       library(MASS)  # 既に読み込んでいれば不要

       ## データの整理 (既に整理してあれば不要)
       TW.data <- transform(read.csv("data/tokyo_weather_reg.csv"),
			    month=substr(as.Date(date),6,7)) # 月を切り出し
       TW.subset  <- transform(subset(TW.data,
				      subset= month %in% c("09","10"),
				      select=c(temp,humid,month)),
			       month=as.factor(month)) # 因子にする

       ## LOO交叉検証法
       lloo <- c()
       qloo <- c() 
       for(i in 1:nrow(TW.subset)) {
           ## 線形
           est <- lda(month ~ temp + humid,
                      data=TW.subset, subset=-i)
           lloo[i] <- predict(est, newdata=TW.subset[i,])$class
           ## 2次
           est <- qda(month ~ temp + humid,
                      data=TW.subset, subset=-i)
           qloo[i] <- predict(est, newdata=TW.subset[i,])$class
       }
       ## l/qloo には LOO交叉検証法による予測値が入っている
       table(Prediction=lloo, Truth=TW.subset$month) # 線形
       table(Prediction=qloo, Truth=TW.subset$month) # 2次

       ## k-重交叉検証法
       lfld <- c()
       qfld <- c() 
       k <- 10 
       blk <- sample(k, nrow(TW.subset), replace=TRUE) 
       for(i in 1:k) {
           idx <- which(blk==i) # 第iブロックのデータ番号を取得
           ## 線形
           est <- lda(month ~ temp + humid,
                      data=TW.subset, subset=-idx)
           lfld[idx] <- predict(est, newdata=TW.subset[idx,])$class
           ## 2次
           est <- qda(month ~ temp + humid,
                      data=TW.subset, subset=-idx)
           qfld[idx] <- predict(est, newdata=TW.subset[idx,])$class
       }
       ## fld には k-重交叉検証法による予測値が入っている
       table(Prediction=lfld, Truth=TW.subset$month) # 線形
       table(Prediction=qfld, Truth=TW.subset$month) # 2次
     #+end_src
     
** R: LOO交叉検証法
   - 関数 ~lda()~ と ~qda()~ はオプションで LOO交叉検証を行うことができる
   - オプションの指定方法
     #+begin_src R :eval no
       est <- lda(formula, data, CV=TRUE)
       est$class # LOO CV による予測結果
       ## 特定のデータを除いて判別関数を構成し，そのデータの予測を行っている
       est <- qda(formula, data, CV=TRUE)
       est$class # LOO CV による予測結果
       ## 2次判別についても同様
     #+end_src
** R: k-重交叉検証法 ~caret::train()~
   - ~caret~ パッケージの関数 ~train()~ で実行可能
     #+begin_src R :eval no
       train(formula, data,
             method,
             trControl=trainControl(method="cv", number))
       ## formula: Rの式 
       ## data: データフレーム
       ## method: 推定を行う関数 method="lda"/"qda" などを指定
       ## trControl: 学習方法の指定
       ## trainControl のオプション
       ##  method: 評価方法など指定 method="cv"/"LOOCV"
       ##  number: k-重交叉検証のブロック数 (k)
     #+end_src

** 練習問題
   :PROPERTIES:
   :reveal_background: #fef4f4
   :END:
   - Wine Quality Data Set を用いた
     線形判別と2次判別に関して，以下を行いなさい
     - LOO交叉検証法を用いて予測誤差の評価を行いなさい
     - k-重交叉検証法を用いて予測誤差の評価を行いなさい
     #+begin_src R :eval no :exports none :tangle yes
       ### 練習2.2
       ### 予測誤差の評価

       ### Wine Quality Data Set による誤差の評価
       library(MASS)  # 既に読み込んでいれば不要
       library(caret) # 既に読み込んでいれば不要

       ## データの整理 (既に整理してあれば不要)
       WQ.org <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv",
			  sep=";")
       WQ.data <- transform(WQ.org,
			    quality=as.factor(
				ifelse(quality %in% 7:10, "A",
				ifelse(quality %in% 5:6, "B" ,"C"))))

       ## LOO CV の例 (lda/qdaは標準で装備している)
       ## 線形判別
       WQ.lda <- lda(quality ~ ., data=WQ.data) 
       WQ.ldloo <- lda(quality ~ ., data=WQ.data, CV=TRUE)
       confusionMatrix(predict(WQ.lda)$class, WQ.data$quality)$table
       confusionMatrix(WQ.ldloo$class, WQ.data$quality)$table
       ## 線形判別の過学習は微小

       ## 2次判別
       WQ.qda <- qda(quality ~ ., data=WQ.data) 
       WQ.qdloo <- qda(quality ~ ., data=WQ.data, CV=TRUE)
       confusionMatrix(predict(WQ.qda)$class, WQ.data$quality)$table
       confusionMatrix(WQ.qdloo$class, WQ.data$quality)$table
       ## 2次判別は若干過学習している

       ## 予測誤差の比較
       confusionMatrix(WQ.ldloo$class, WQ.data$quality)$overall
       confusionMatrix(WQ.qdloo$class, WQ.data$quality)$overall
       ## 予測誤差の観点からは線形判別の方が良さそう

       ## k-重交叉検証は caret package の機能を利用して求めることができる
       (train(quality ~., data=WQ.data, method="lda",
		    trControl=trainControl(method="cv", number=10)))
       (train(quality ~., data=WQ.data, method="qda",
		    trControl=trainControl(method="cv", number=10)))
       ## LOO CV も利用することができるが，計算は遅い
       (train(quality ~., data=WQ.data, method="lda",
		    trControl=trainControl(method="LOOCV")))
       (train(quality ~., data=WQ.data, method="qda",
		    trControl=trainControl(method="LOOCV")))
     #+end_src
  
** COMMENT 演習: 予測誤差の評価
   :PROPERTIES:
   :reveal_background: #EEEEFF
   :END:
   - [[./code/10-valid.r][10-valid.r]] を確認してみよう

** COMMENT 演習: 交叉検証による評価
   :PROPERTIES:
   :reveal_background: #EEEEFF
   :END:
   - [[./code/10-cv.r][10-cv.r]] を確認してみよう

** COMMENT 演習
   :PROPERTIES:
   :reveal_background: #EEEEFF
   :END:
   - 前回用いたデータについて線形・2次どちらの判別方法が望ましいか検証してみよう


* 次週の予定
  - *第1日: クラスター分析と階層的クラスタリング*
  - 第2日: 非階層的クラスタリング

* COMMENT ローカル変数
# Local Variables:
# org-latex-listings: minted
# End:
  
   
   
