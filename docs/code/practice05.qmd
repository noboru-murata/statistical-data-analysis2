---
title: "統計データ解析"
subtitle: "第5講 実習"
date: "`r Sys.Date()`"
format:
    html: 
      toc: true
      html-math-method: katex
      self-contained: true
      grid: 
        margin-width: 350px
execute: 
  echo: true
  warning: false
reference-location: margin
citation-location: margin
tbl-cap-location: margin
fig-cap-location: margin
editor: visual
editor_options: 
  chunk_output_type: console
---

## 準備

以下で利用する共通パッケージを読み込む．

```{r}
library(conflicted) # 関数名の衝突を警告
conflicts_prefer(   # 優先的に使う関数を指定
  dplyr::filter(),
  dplyr::select(),
  dplyr::lag(),
  )
library(tidyverse)  
library(broom)      # 解析結果を tibble 形式に集約
library(ggfortify)  # 診断プロットの描画
library(gt)         # 表の作成
library(gtsummary)  # 分析結果の表の作成
```

## 人工データによる予測の例

以下はあくまで例なので自由に数値実験を設計して下さい．

人工データを生成する．

```{r}
#' モデル: y = -1 + 2 * x1
set.seed(1515) # 乱数のシード値(適宜変更せよ)
n <- 50 # データ数の設定
x_obs <- tibble(x0 = 1,
                x1 = runif(n), # 説明変数1
                x2 = runif(n)) # 説明変数2
beta <- c(-1, 2, 0) # (切片, x1の係数, x2の係数) 実質x2は使われていない
sigma <-  1/2 # 誤差の標準偏差
epsilon <- rnorm(nrow(x_obs), sd = sigma) # 誤差項
toy_data <- x_obs |> # 目的変数の観測値を追加
    mutate(y = as.vector(as.matrix(x_obs) %*% beta) + epsilon)
```

モデルの推定と評価を行う．

```{r}
toy_lm1 <- lm(y ~ x1, data = toy_data)      # x1のみの正しいモデル
toy_lm2 <- lm(y ~ x1 + x2, data = toy_data) # x1とx2の冗長なモデル
toy_lm3 <- lm(y ~ x2, data = toy_data)      # x2のみの誤ったモデル
summary(toy_lm1)
summary(toy_lm2)
summary(toy_lm3)
```

表としてまとめるには，例えば以下のようにすればよい．

```{r}
my_gts <- function(x){
    tbl_regression(x, intercept = TRUE) |>
        add_significance_stars(
            pattern = "{estimate} ({conf.low}, {conf.high}){stars}",
            hide_ci = TRUE, hide_se = TRUE
        ) |>
        modify_header(estimate = "**Beta (95% CI)**") |>
        modify_footnote(estimate = "CI = Confidence Interval",
                        abbreviation = TRUE) |>
        add_glance_table(include = c(r.squared,
                                     adj.r.squared,
                                     statistic,
                                     p.value)) }
tbl_merge(
    tbls = list(
        my_gts(toy_lm1),
        my_gts(toy_lm2),
        my_gts(toy_lm3)),
    tab_spanner = c("モデル1","モデル2","モデル3")) |>
    modify_table_body( ~ .x |>
                           arrange(factor(variable,
                                          levels = c("(Intercept)","x1","x2"))))
```

新規データに対する予測の仕組みを確認する．

```{r}
x_new <- tibble(x0 = 1,
                x1 = runif(n),
                x2 = runif(n,-10,10)) 
#' 新規データに対する目的変数の真値 (誤差なし)
y_tilde <- as.vector(as.matrix(x_new) %*% beta)
#' 各モデルでの予測
y_hat1 <- predict(toy_lm1, newdata = x_new) # x_lm1による予測値
y_hat2 <- predict(toy_lm2, newdata = x_new) # x_lm2による予測値
y_hat3 <- predict(toy_lm3, newdata = x_new) # x_lm3による予測値
```

散布図を用いて，それぞれのモデルによる予測値と真値の関係を可視化する．

```{r}
tibble(obs = y_tilde,
       model1 = y_hat1, model2 = y_hat2, model3 = y_hat3) |>
    pivot_longer(!obs) |>
    ggplot(aes(x = value, y = obs)) +
    geom_point(aes(colour = name)) +
    geom_abline(slope = 1, intercept = 0, colour = "gray") +
    labs(x = "fitted value", y = "observed value") +
    theme(legend.title = element_blank())
```

正しいモデルでは正確に予測が行われているが，不要な項が含まれると予測誤差が大きくなることがわかる．

雑音のないデータ $\tilde{y}$ と予測値の相関係数(2乗すると決定係数に相当)を用いて数値的な評価をする．

```{r}
cor(y_tilde, y_hat1)^2 
cor(y_tilde, y_hat2)^2
cor(y_tilde, y_hat3)^2
```

## 回帰式を用いた予測

### 問題

東京の気候データを用いて以下の実験を試みなさい．

-   8月のデータで回帰式を推定する
-   上記のモデルで9月のデータを予測する

特定の月のデータを取り出すには，例えば以下のようにすればよい

``` r
tw_data <- read_csv("data/tokyo_weather.csv")
tw_train <- tw_data |> filter(month == 8) # 単一の数字と比較
tw_test  <- tw_data |> filter(month %in% c(9,10)) # 集合と比
```

```{r}

```

## 非線形性を含むモデルとカテゴリカル変数の扱い

### 問題

東京の気候データ(9-11月)を用いて，気温を回帰する以下のモデルを検討しなさい．

-   日射量，気圧，湿度の線形回帰モデル
-   湿度の対数を考えた線形回帰モデル
-   最初のモデルにそれぞれの交互作用を加えたモデル

東京の気候データ(1年分)を用いて，気温を回帰する以下のモデルを検討しなさい．

-   降水の有無を表すカテゴリカル変数を用いたモデル (雨が降ると気温が変化することを検証する)
-   上記に月をカテゴリカル変数として加えたモデル (月毎の気温の差を考慮する)

```{r}

```
